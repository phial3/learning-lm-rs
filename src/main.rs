mod api;
mod chat;
mod config;
mod kvcache;
mod model;
mod operators;
mod params;
mod tensor;

use crate::chat::Chat;
use crate::config::LlamaConfigJson;
use crate::params::ChatParams;
use safetensors::SafeTensors;
use std::fs;
use std::io::{self, Write};
use std::path::PathBuf;
use tokenizers::Tokenizer;

fn print_banner() {
    println!("\nğŸ¤– Welcome to My Rust4LLM Console");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("Available modes:");
    println!("1. Story - Creative writing mode");
    println!("2. Chat - Interactive conversation mode");
    println!("3. API - Start API service");
    println!("4. Exit");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
}

fn get_user_input(prompt: &str) -> String {
    print!("{}", prompt);
    io::stdout().flush().unwrap();
    let mut input = String::new();
    io::stdin().read_line(&mut input).unwrap();
    input.trim().to_string()
}

fn chat_mode() {
    // åŠ è½½èŠå¤©æ¨¡å‹
    println!("\nğŸ“š Loading chat model...");
    let config = LlamaConfigJson::from_file("models/chat/config.json".into());

    // åˆ›å»ºtokenizer
    let tokenizer = Tokenizer::from_file("models/chat/tokenizer.json").unwrap();

    let model_data = fs::read("models/chat/model.safetensors").unwrap();
    let params =
        ChatParams::from_safetensors(&SafeTensors::deserialize(&model_data).unwrap(), &config);
    let mut chat = Chat::new(params, tokenizer, config);

    // è®¾ç½®èŠå¤©æ¨¡å¼çš„ç³»ç»Ÿæç¤º
    chat.set_system_message(
        "You are a helpful AI assistant. Please provide clear, concise, and accurate responses. \
        Be friendly and professional."
            .to_string(),
    );

    println!("âœ¨ Chat mode initialized! Type 'exit' to return to main menu.");
    println!("ğŸ’¡ Type 'clear' to clear chat history.");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

    loop {
        let input = get_user_input("\nYou: ");
        if input.to_lowercase() == "exit" {
            break;
        } else if input.to_lowercase() == "clear" {
            chat.clear_history();
            println!("ğŸ§¹ Chat history cleared!");
            continue;
        }

        print!("Assistant: ");
        io::stdout().flush().unwrap();
        let _response = chat.chat(&input);
        println!("\n");
    }
}

fn story_mode() {
    // åŠ è½½æ•…äº‹æ¨¡å‹
    println!("\nğŸ“š Loading story model...");
    let model_dir = PathBuf::from("models").join("story");
    let llama = model::Llama::<f32>::from_safetensors(&model_dir);
    let tokenizer = Tokenizer::from_file(model_dir.join("tokenizer.json")).unwrap();

    println!("âœ¨ Story mode initialized! Type 'exit' to return to main menu.");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

    loop {
        let input = get_user_input("\nStory beginning: ");
        if input.to_lowercase() == "exit" {
            break;
        }

        print!("\nGenerating story continuation...\n\n");
        io::stdout().flush().unwrap();

        // ä½¿ç”¨ model.rs ä¸­çš„ generate å‡½æ•°
        let tokens = tokenizer.encode(input.as_str(), true).unwrap();
        let input_ids = tokens.get_ids();
        let output_ids = llama.generate(input_ids, 1000, 0.95, 40, 0.8);

        print!("{}", input);
        println!(
            "{}\n",
            tokenizer
                .decode(&output_ids[input_ids.len()..], true)
                .unwrap()
        );
        println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    }
}

fn api_mode() {
    println!("\nğŸŒ Starting API service...");

    // æä¾›å¯ä»¥è®¿é—®storyæ¨¡å‹å’Œchatæ¨¡å‹çš„APIæœåŠ¡
    match api::start_api_server() {
        Ok(_) => println!("APIæœåŠ¡å·²åœæ­¢"),
        Err(e) => println!("APIæœåŠ¡å¯åŠ¨å¤±è´¥: {}", e),
    }
}

fn main() {
    loop {
        print_banner();

        match get_user_input("Please select a mode (1-4): ").as_str() {
            "1" => story_mode(),
            "2" => chat_mode(),
            "3" => api_mode(),
            "4" => {
                println!("\nğŸ‘‹ Goodbye!");
                break;
            }
            _ => println!("\nâŒ Invalid choice. Please try again."),
        }
    }
}
